{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e01a8839-263b-4bad-862e-354d4c58357d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded blinds_1_cleaned.csv: (2184, 69)\n",
      "  Loaded blinds_2_cleaned.csv: (2060, 70)\n",
      "  Loaded blinds_3_cleaned.csv: (1919, 70)\n",
      "  Loaded blinds_4_cleaned.csv: (449, 69)\n",
      "  Loaded blinds_5_cleaned.csv: (427, 58)\n",
      "  Loaded blinds_motion_1_cleaned.csv: (2004, 66)\n",
      "  Loaded blinds_motion_2_cleaned.csv: (452, 65)\n",
      "  Loaded blinds_motion_3_cleaned.csv: (464, 59)\n",
      "  Loaded blinds_motion_4_cleaned.csv: (436, 58)\n",
      "  Loaded blinds_motion_5_cleaned.csv: (477, 60)\n",
      "  Loaded blinds_object_1_cleaned.csv: (2044, 62)\n",
      "  Loaded blinds_object_2_cleaned.csv: (443, 59)\n",
      "  Loaded blinds_object_3_cleaned.csv: (443, 59)\n",
      "  Loaded blinds_object_4_cleaned.csv: (455, 59)\n",
      "  Loaded blinds_object_5_cleaned.csv: (2036, 59)\n",
      "  Loaded blinds_person_1_cleaned.csv: (466, 68)\n",
      "  Loaded blinds_person_2_cleaned.csv: (446, 64)\n",
      "  Loaded blinds_person_3_cleaned.csv: (477, 58)\n",
      "  Loaded blinds_person_4_cleaned.csv: (482, 59)\n",
      "  Loaded blinds_person_5_cleaned.csv: (449, 59)\n",
      "  Loaded blinds_up_1_cleaned.csv: (103, 24)\n",
      "  Loaded blinds_up_2_cleaned.csv: (1775, 24)\n",
      "  Loaded blinds_up_3_cleaned.csv: (1795, 25)\n",
      "  Loaded blinds_up_4_cleaned.csv: (1798, 25)\n",
      "  Loaded blinds_up_5_cleaned.csv: (101, 24)\n",
      "  Loaded blinds_up_motion_1_cleaned.csv: (467, 62)\n",
      "  Loaded blinds_up_motion_2_cleaned.csv: (2094, 63)\n",
      "  Loaded blinds_up_motion_3_cleaned.csv: (472, 64)\n",
      "  Loaded blinds_up_motion_4_cleaned.csv: (2005, 71)\n",
      "  Loaded blinds_up_motion_5_cleaned.csv: (2109, 65)\n",
      "  Loaded blinds_up_object_1_cleaned.csv: (1946, 66)\n",
      "  Loaded blinds_up_object_2_cleaned.csv: (1981, 59)\n",
      "  Loaded blinds_up_object_3_cleaned.csv: (2013, 60)\n",
      "  Loaded blinds_up_object_4_cleaned.csv: (473, 59)\n",
      "  Loaded blinds_up_object_5_cleaned.csv: (2079, 60)\n",
      "  Loaded blinds_up_person_1_cleaned.csv: (2042, 38)\n",
      "  Loaded blinds_up_person_2_cleaned.csv: (1979, 61)\n",
      "  Loaded blinds_up_person_3_cleaned.csv: (493, 58)\n",
      "  Loaded blinds_up_person_4_cleaned.csv: (425, 58)\n",
      "  Loaded blinds_up_person_5_cleaned.csv: (461, 59)\n",
      "  Loaded hallway_1_cleaned.csv: (409, 59)\n",
      "  Loaded hallway_2_cleaned.csv: (407, 59)\n",
      "  Loaded hallway_3_cleaned.csv: (457, 59)\n",
      "  Loaded hallway_4_cleaned.csv: (438, 58)\n",
      "  Loaded hallway_5_cleaned.csv: (1981, 70)\n",
      "  Loaded hallway_motion_1_cleaned.csv: (467, 59)\n",
      "  Loaded hallway_motion_2_cleaned.csv: (482, 60)\n",
      "  Loaded hallway_motion_3_cleaned.csv: (449, 58)\n",
      "  Loaded hallway_motion_4_cleaned.csv: (1981, 60)\n",
      "  Loaded hallway_motion_5_cleaned.csv: (458, 59)\n",
      "  Loaded hallway_object_1_cleaned.csv: (2724, 69)\n",
      "  Loaded hallway_object_2_cleaned.csv: (1931, 70)\n",
      "  Loaded hallway_object_3_cleaned.csv: (1953, 60)\n",
      "  Loaded hallway_object_4_cleaned.csv: (457, 59)\n",
      "  Loaded hallway_object_5_cleaned.csv: (455, 59)\n",
      "  Loaded hallway_person_1_cleaned.csv: (452, 69)\n",
      "  Loaded hallway_person_2_cleaned.csv: (1996, 69)\n",
      "  Loaded hallway_person_3_cleaned.csv: (495, 58)\n",
      "  Loaded hallway_person_4_cleaned.csv: (2129, 59)\n",
      "  Loaded hallway_person_5_cleaned.csv: (1974, 59)\n",
      "  Loaded kitchen_10_cleaned.csv: (2190, 70)\n",
      "  Loaded kitchen_1_cleaned.csv: (439, 58)\n",
      "  Loaded kitchen_2_cleaned.csv: (447, 59)\n",
      "  Loaded kitchen_3_cleaned.csv: (485, 69)\n",
      "  Loaded kitchen_4_cleaned.csv: (1874, 68)\n",
      "  Loaded kitchen_5_cleaned.csv: (1923, 38)\n",
      "  Loaded kitchen_6_cleaned.csv: (401, 63)\n",
      "  Loaded kitchen_7_cleaned.csv: (1974, 34)\n",
      "  Loaded kitchen_8_cleaned.csv: (451, 35)\n",
      "  Loaded kitchen_9_cleaned.csv: (2108, 69)\n",
      "  Loaded kitchen_motion_1_cleaned.csv: (417, 65)\n",
      "  Loaded kitchen_motion_2_cleaned.csv: (1899, 67)\n",
      "  Loaded kitchen_motion_3_cleaned.csv: (1937, 60)\n",
      "  Loaded kitchen_motion_4_cleaned.csv: (443, 58)\n",
      "  Loaded kitchen_motion_5_cleaned.csv: (497, 59)\n",
      "  Loaded kitchen_object_1_cleaned.csv: (2005, 65)\n",
      "  Loaded kitchen_object_2_cleaned.csv: (426, 66)\n",
      "  Loaded kitchen_object_3_cleaned.csv: (2015, 60)\n",
      "  Loaded kitchen_object_4_cleaned.csv: (1997, 59)\n",
      "  Loaded kitchen_object_5_cleaned.csv: (476, 60)\n",
      "  Loaded kitchen_person_1_cleaned.csv: (2133, 35)\n",
      "  Loaded kitchen_person_2_cleaned.csv: (501, 67)\n",
      "  Loaded kitchen_person_3_cleaned.csv: (1917, 59)\n",
      "  Loaded kitchen_person_4_cleaned.csv: (477, 59)\n",
      "  Loaded kitchen_person_5_cleaned.csv: (412, 59)\n",
      "  Loaded lab_1_cleaned.csv: (1925, 69)\n",
      "  Loaded lab_2_cleaned.csv: (438, 68)\n",
      "  Loaded lab_3_cleaned.csv: (474, 58)\n",
      "  Loaded lab_4_cleaned.csv: (471, 58)\n",
      "  Loaded lab_5_cleaned.csv: (1980, 60)\n",
      "  Loaded lab_motion_1_cleaned.csv: (423, 58)\n",
      "  Loaded lab_motion_2_cleaned.csv: (453, 69)\n",
      "  Loaded lab_motion_3_cleaned.csv: (479, 70)\n",
      "  Loaded lab_motion_4_cleaned.csv: (455, 69)\n",
      "  Loaded lab_motion_5_cleaned.csv: (2028, 69)\n",
      "  Loaded lab_object_1_cleaned.csv: (2046, 69)\n",
      "  Loaded lab_object_2_cleaned.csv: (1970, 59)\n",
      "  Loaded lab_object_3_cleaned.csv: (469, 58)\n",
      "  Loaded lab_object_4_cleaned.csv: (392, 59)\n",
      "  Loaded lab_object_5_cleaned.csv: (447, 58)\n",
      "  Loaded lab_person_1_cleaned.csv: (440, 70)\n",
      "  Loaded lab_person_2_cleaned.csv: (2179, 70)\n",
      "  Loaded lab_person_3_cleaned.csv: (434, 67)\n",
      "  Loaded lab_person_4_cleaned.csv: (378, 32)\n",
      "  Loaded lab_person_5_cleaned.csv: (471, 58)\n",
      "================================================================================\n",
      "DATA INVENTORY SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total CSV files: 105\n",
      "\n",
      "Room types (5): ['blinds', 'blinds_up', 'hallway', 'kitchen', 'lab']\n",
      "Scan types (4): ['base', 'motion', 'object', 'person']\n",
      "\n",
      "================================================================================\n",
      "COUNTS BY ROOM TYPE AND SCAN TYPE\n",
      "================================================================================\n",
      "scan_type  base  motion  object  person\n",
      "room_type                              \n",
      "blinds        5       5       5       5\n",
      "blinds_up     5       5       5       5\n",
      "hallway       5       5       5       5\n",
      "kitchen      10       5       5       5\n",
      "lab           5       5       5       5\n",
      "\n",
      "Total scans per room type:\n",
      "room_type\n",
      "blinds       20\n",
      "blinds_up    20\n",
      "hallway      20\n",
      "kitchen      25\n",
      "lab          20\n",
      "dtype: int64\n",
      "\n",
      "================================================================================\n",
      "ROW COUNTS STATISTICS BY ROOM TYPE\n",
      "================================================================================\n",
      "           count     mean     std    min     25%     50%      75%     max\n",
      "room_type                                                                \n",
      "blinds      20.0   930.65  747.32  427.0  448.25   465.0  1940.25  2184.0\n",
      "blinds_up   20.0  1330.55  812.55  101.0  470.75  1796.5  2007.00  2109.0\n",
      "hallway     20.0  1104.75  835.92  407.0  454.25   474.5  1975.75  2724.0\n",
      "kitchen     25.0  1193.76  791.52  401.0  447.00   501.0  1974.00  2190.0\n",
      "lab         20.0   917.60  743.15  378.0  439.50   470.0  1936.25  2179.0\n",
      "\n",
      "================================================================================\n",
      "SAMPLE FILES (sorted by room_type, scan_type, trial)\n",
      "================================================================================\n",
      "                       filename room_type scan_type  trial_number  num_rows\n",
      "0          blinds_1_cleaned.csv    blinds      base             1      2184\n",
      "1          blinds_2_cleaned.csv    blinds      base             2      2060\n",
      "2          blinds_3_cleaned.csv    blinds      base             3      1919\n",
      "3          blinds_4_cleaned.csv    blinds      base             4       449\n",
      "4          blinds_5_cleaned.csv    blinds      base             5       427\n",
      "5   blinds_motion_1_cleaned.csv    blinds    motion             1      2004\n",
      "6   blinds_motion_2_cleaned.csv    blinds    motion             2       452\n",
      "7   blinds_motion_3_cleaned.csv    blinds    motion             3       464\n",
      "8   blinds_motion_4_cleaned.csv    blinds    motion             4       436\n",
      "9   blinds_motion_5_cleaned.csv    blinds    motion             5       477\n",
      "10  blinds_object_1_cleaned.csv    blinds    object             1      2044\n",
      "11  blinds_object_2_cleaned.csv    blinds    object             2       443\n",
      "12  blinds_object_3_cleaned.csv    blinds    object             3       443\n",
      "13  blinds_object_4_cleaned.csv    blinds    object             4       455\n",
      "14  blinds_object_5_cleaned.csv    blinds    object             5      2036\n",
      "\n",
      "================================================================================\n",
      "VERIFICATION\n",
      "================================================================================\n",
      "Expected: 105 scans (5 room types × 4 scan types × 5 trials + 5 extra kitchen base scans)\n",
      "Actual: 105 scans\n",
      "✓ Count matches!\n",
      "\n",
      "✓ Saved complete inventory to: meta_scan_csvs/data_inventory.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def parse_filename(filepath):\n",
    "    \"\"\"\n",
    "    Parse filename to extract room_type, scan_type, and trial_number\n",
    "    Examples:\n",
    "    - blinds_1_cleaned.csv -> room: blinds, scan: base, trial: 1\n",
    "    - blinds_up_1_cleaned.csv -> room: blinds_up, scan: base, trial: 1\n",
    "    - kitchen_motion_3_cleaned.csv -> room: kitchen, scan: motion, trial: 3\n",
    "    \"\"\"\n",
    "    filename = filepath.stem.replace('_cleaned', '')\n",
    "    \n",
    "    # Handle blinds_up as a special case (two-word room type)\n",
    "    if filename.startswith('blinds_up'):\n",
    "        room_type = 'blinds_up'\n",
    "        remainder = filename.replace('blinds_up_', '', 1)\n",
    "    else:\n",
    "        # Split and take first part as room type\n",
    "        parts = filename.split('_')\n",
    "        room_type = parts[0]\n",
    "        remainder = '_'.join(parts[1:])\n",
    "    \n",
    "    # Now parse the remainder for scan type and trial\n",
    "    remainder_parts = remainder.split('_')\n",
    "    \n",
    "    if len(remainder_parts) == 1:\n",
    "        # Base scan (just a number)\n",
    "        scan_type = 'base'\n",
    "        trial_number = int(remainder_parts[0])\n",
    "    elif len(remainder_parts) == 2:\n",
    "        # Scan type + number (e.g., motion_3)\n",
    "        scan_type = remainder_parts[0]\n",
    "        trial_number = int(remainder_parts[1])\n",
    "    else:\n",
    "        scan_type = 'unknown'\n",
    "        trial_number = -1\n",
    "    \n",
    "    return room_type, scan_type, trial_number\n",
    "\n",
    "# Scan all CSV files\n",
    "cleaned_path = Path(\"meta_scan_csvs/cleaned\")\n",
    "csv_files = list(cleaned_path.rglob(\"*.csv\"))\n",
    "\n",
    "# Create metadata inventory\n",
    "metadata = []\n",
    "for csv_file in csv_files:\n",
    "    room_type, scan_type, trial_number = parse_filename(csv_file)\n",
    "    \n",
    "    # Get number of rows\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(f\"  Loaded {csv_file.name}: {df.shape}\")\n",
    "    num_rows = len(df)\n",
    "    \n",
    "    metadata.append({\n",
    "        'filepath': str(csv_file),\n",
    "        'filename': csv_file.name,\n",
    "        'room_type': room_type,\n",
    "        'scan_type': scan_type,\n",
    "        'trial_number': trial_number,\n",
    "        'num_rows': num_rows,\n",
    "        'folder': csv_file.parent.name\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "metadata_df = pd.DataFrame(metadata)\n",
    "\n",
    "# Display summary\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA INVENTORY SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal CSV files: {len(metadata_df)}\")\n",
    "print(f\"\\nRoom types ({len(metadata_df['room_type'].unique())}): {sorted(metadata_df['room_type'].unique())}\")\n",
    "print(f\"Scan types ({len(metadata_df['scan_type'].unique())}): {sorted(metadata_df['scan_type'].unique())}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COUNTS BY ROOM TYPE AND SCAN TYPE\")\n",
    "print(\"=\" * 80)\n",
    "pivot = metadata_df.groupby(['room_type', 'scan_type']).size().unstack(fill_value=0)\n",
    "print(pivot)\n",
    "print(f\"\\nTotal scans per room type:\")\n",
    "print(pivot.sum(axis=1))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ROW COUNTS STATISTICS BY ROOM TYPE\")\n",
    "print(\"=\" * 80)\n",
    "print(metadata_df.groupby('room_type')['num_rows'].describe().round(2))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAMPLE FILES (sorted by room_type, scan_type, trial)\")\n",
    "print(\"=\" * 80)\n",
    "sample = metadata_df.sort_values(['room_type', 'scan_type', 'trial_number'])\n",
    "print(sample[['filename', 'room_type', 'scan_type', 'trial_number', 'num_rows']].head(15))\n",
    "\n",
    "# Verify we have exactly 105 scans\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Expected: 105 scans (5 room types × 4 scan types × 5 trials + 5 extra kitchen base scans)\")\n",
    "print(f\"Actual: {len(metadata_df)} scans\")\n",
    "if len(metadata_df) == 105:\n",
    "    print(\"✓ Count matches!\")\n",
    "else:\n",
    "    print(\"⚠ Count mismatch - please review\")\n",
    "\n",
    "# Save metadata to CSV for reference\n",
    "metadata_df.to_csv(\"meta_scan_csvs/data_inventory.csv\", index=False)\n",
    "print(f\"\\n✓ Saved complete inventory to: meta_scan_csvs/data_inventory.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "715b2fc0-ec3c-4ae4-9fbb-49cf98095ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STRATIFIED TRAIN/TEST SPLIT (80/20)\n",
      "================================================================================\n",
      "\n",
      "Total files: 105\n",
      "Training files: 84 (80.0%)\n",
      "Testing files: 21 (20.0%)\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET DISTRIBUTION\n",
      "================================================================================\n",
      "scan_type  base  motion  object  person\n",
      "room_type                              \n",
      "blinds        4       4       4       4\n",
      "blinds_up     4       4       4       4\n",
      "hallway       4       4       4       4\n",
      "kitchen       8       4       4       4\n",
      "lab           4       4       4       4\n",
      "\n",
      "Total per room type:\n",
      "room_type\n",
      "blinds       16\n",
      "blinds_up    16\n",
      "hallway      16\n",
      "kitchen      20\n",
      "lab          16\n",
      "dtype: int64\n",
      "\n",
      "================================================================================\n",
      "TESTING SET DISTRIBUTION\n",
      "================================================================================\n",
      "scan_type  base  motion  object  person\n",
      "room_type                              \n",
      "blinds        1       1       1       1\n",
      "blinds_up     1       1       1       1\n",
      "hallway       1       1       1       1\n",
      "kitchen       2       1       1       1\n",
      "lab           1       1       1       1\n",
      "\n",
      "Total per room type:\n",
      "room_type\n",
      "blinds       4\n",
      "blinds_up    4\n",
      "hallway      4\n",
      "kitchen      5\n",
      "lab          4\n",
      "dtype: int64\n",
      "\n",
      "================================================================================\n",
      "FILES SAVED\n",
      "================================================================================\n",
      "✓ meta_scan_csvs/train_metadata.csv\n",
      "✓ meta_scan_csvs/test_metadata.csv\n",
      "\n",
      "================================================================================\n",
      "SAMPLE TRAINING FILES\n",
      "================================================================================\n",
      "                           filename  room_type scan_type  trial_number\n",
      "102        lab_person_3_cleaned.csv        lab    person             3\n",
      "86                lab_2_cleaned.csv        lab      base             2\n",
      "35   blinds_up_person_1_cleaned.csv  blinds_up    person             1\n",
      "37   blinds_up_person_3_cleaned.csv  blinds_up    person             3\n",
      "29   blinds_up_motion_5_cleaned.csv  blinds_up    motion             5\n",
      "75     kitchen_object_1_cleaned.csv    kitchen    object             1\n",
      "4              blinds_5_cleaned.csv     blinds      base             5\n",
      "59     hallway_person_5_cleaned.csv    hallway    person             5\n",
      "6       blinds_motion_2_cleaned.csv     blinds    motion             2\n",
      "89                lab_5_cleaned.csv        lab      base             5\n",
      "\n",
      "================================================================================\n",
      "SAMPLE TESTING FILES\n",
      "================================================================================\n",
      "                           filename  room_type scan_type  trial_number\n",
      "24          blinds_up_5_cleaned.csv  blinds_up      base             5\n",
      "48     hallway_motion_4_cleaned.csv    hallway    motion             4\n",
      "9       blinds_motion_5_cleaned.csv     blinds    motion             5\n",
      "76     kitchen_object_2_cleaned.csv    kitchen    object             2\n",
      "38   blinds_up_person_4_cleaned.csv  blinds_up    person             4\n",
      "101        lab_person_2_cleaned.csv        lab    person             2\n",
      "83     kitchen_person_4_cleaned.csv    kitchen    person             4\n",
      "12      blinds_object_3_cleaned.csv     blinds    object             3\n",
      "93         lab_motion_4_cleaned.csv        lab    motion             4\n",
      "19      blinds_person_5_cleaned.csv     blinds    person             5\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the inventory we just created\n",
    "metadata_df = pd.read_csv(\"meta_scan_csvs/data_inventory.csv\")\n",
    "\n",
    "# Create a stratification column combining room_type and scan_type\n",
    "metadata_df['strata'] = metadata_df['room_type'] + '_' + metadata_df['scan_type']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STRATIFIED TRAIN/TEST SPLIT (80/20)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Perform stratified split\n",
    "train_df, test_df = train_test_split(\n",
    "    metadata_df,\n",
    "    test_size=0.2,\n",
    "    stratify=metadata_df['strata'],\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal files: {len(metadata_df)}\")\n",
    "print(f\"Training files: {len(train_df)} ({len(train_df)/len(metadata_df)*100:.1f}%)\")\n",
    "print(f\"Testing files: {len(test_df)} ({len(test_df)/len(metadata_df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING SET DISTRIBUTION\")\n",
    "print(\"=\" * 80)\n",
    "train_dist = train_df.groupby(['room_type', 'scan_type']).size().unstack(fill_value=0)\n",
    "print(train_dist)\n",
    "print(f\"\\nTotal per room type:\\n{train_dist.sum(axis=1)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TESTING SET DISTRIBUTION\")\n",
    "print(\"=\" * 80)\n",
    "test_dist = test_df.groupby(['room_type', 'scan_type']).size().unstack(fill_value=0)\n",
    "print(test_dist)\n",
    "print(f\"\\nTotal per room type:\\n{test_dist.sum(axis=1)}\")\n",
    "\n",
    "# Save the splits\n",
    "train_df.to_csv(\"meta_scan_csvs/train_metadata.csv\", index=False)\n",
    "test_df.to_csv(\"meta_scan_csvs/test_metadata.csv\", index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FILES SAVED\")\n",
    "print(\"=\" * 80)\n",
    "print(\"✓ meta_scan_csvs/train_metadata.csv\")\n",
    "print(\"✓ meta_scan_csvs/test_metadata.csv\")\n",
    "\n",
    "# Show some examples\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAMPLE TRAINING FILES\")\n",
    "print(\"=\" * 80)\n",
    "print(train_df[['filename', 'room_type', 'scan_type', 'trial_number']].head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAMPLE TESTING FILES\")\n",
    "print(\"=\" * 80)\n",
    "print(test_df[['filename', 'room_type', 'scan_type', 'trial_number']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ca7845-0aed-4768-976c-3be7bfa2b4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sktime in c:\\users\\gkamt\\anaconda3\\lib\\site-packages (0.39.0)\n",
      "Requirement already satisfied: joblib<1.6,>=1.2.0 in c:\\users\\gkamt\\anaconda3\\lib\\site-packages (from sktime) (1.4.2)\n",
      "Requirement already satisfied: numpy<2.4,>=1.21 in c:\\users\\gkamt\\anaconda3\\lib\\site-packages (from sktime) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\gkamt\\anaconda3\\lib\\site-packages (from sktime) (24.1)\n",
      "Requirement already satisfied: pandas<2.4.0,>=1.1 in c:\\users\\gkamt\\anaconda3\\lib\\site-packages (from sktime) (2.2.2)\n",
      "Requirement already satisfied: scikit-base<0.13.0,>=0.6.1 in c:\\users\\gkamt\\anaconda3\\lib\\site-packages (from sktime) (0.12.6)\n",
      "Requirement already satisfied: scikit-learn<1.8.0,>=0.24 in c:\\users\\gkamt\\anaconda3\\lib\\site-packages (from sktime) (1.5.1)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.2 in c:\\users\\gkamt\\anaconda3\\lib\\site-packages (from sktime) (1.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gkamt\\anaconda3\\lib\\site-packages (from pandas<2.4.0,>=1.1->sktime) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gkamt\\anaconda3\\lib\\site-packages (from pandas<2.4.0,>=1.1->sktime) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gkamt\\anaconda3\\lib\\site-packages (from pandas<2.4.0,>=1.1->sktime) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gkamt\\anaconda3\\lib\\site-packages (from scikit-learn<1.8.0,>=0.24->sktime) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gkamt\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<2.4.0,>=1.1->sktime) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sktime --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5331af0c-9b67-4237-a376-289c2e4fe092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ANALYZING SENSOR COLUMNS ACROSS ROOMS\n",
      "================================================================================\n",
      "\n",
      "blinds: 68 columns\n",
      "  Sample columns: ['% Linear Filtered', '% Nearest Filtered', '% Non-Base Level Textures', '% Prims Clipped', '% Prims Trivially Rejected']\n",
      "\n",
      "blinds_up: 23 columns\n",
      "  Sample columns: ['app_gpu_ms', 'app_rss_mb', 'app_uss_mb', 'app_vss_mb', 'application_layer_count']\n",
      "\n",
      "hallway: 58 columns\n",
      "  Sample columns: ['% Prims Clipped', '% Prims Trivially Rejected', '% Stalled on System Memory', '% Texture L2 Miss', '% Vertex Fetch Stall']\n",
      "\n",
      "kitchen: 57 columns\n",
      "  Sample columns: ['% Prims Clipped', '% Prims Trivially Rejected', '% Stalled on System Memory', '% Texture L2 Miss', '% Vertex Fetch Stall']\n",
      "\n",
      "lab: 68 columns\n",
      "  Sample columns: ['% Linear Filtered', '% Nearest Filtered', '% Non-Base Level Textures', '% Prims Clipped', '% Prims Trivially Rejected']\n",
      "\n",
      "================================================================================\n",
      "COMMON COLUMNS ACROSS ALL ROOMS: 22\n",
      "================================================================================\n",
      "['app_gpu_ms', 'app_rss_mb', 'app_uss_mb', 'app_vss_mb', 'application_layer_count', 'application_prediction_milliseconds', 'available_memory_mb', 'cpu_frequency_mhz', 'cpu_level', 'cpu_util_0', 'cpu_util_1', 'cpu_util_2', 'cpu_util_3', 'cpu_util_4', 'cpu_util_5', 'display_refresh_rate', 'gpu_frequency_mhz', 'gpu_level', 'gpu_util', 'mem_frequency_mhz', 'stale_frames_per_second', 'timewarp_gpu_ms']\n",
      "\n",
      "================================================================================\n",
      "UNIQUE COLUMNS PER ROOM\n",
      "================================================================================\n",
      "\n",
      "blinds: 46 unique columns\n",
      "  Examples: ['% Texture Fetch Stall', 'Average Polygon Area', 'Pre-clipped Polygons/Second', 'SP Memory Read (Bytes/Second)', 'GPU % Bus Busy']\n",
      "\n",
      "blinds_up: 1 unique columns\n",
      "  Examples: ['screen_tears_per_second']\n",
      "\n",
      "hallway: 36 unique columns\n",
      "  Examples: ['Average Polygon Area', 'Pre-clipped Polygons/Second', 'GPU % Bus Busy', 'SP Memory Read (Bytes/Second)', '% Vertex Fetch Stall']\n",
      "\n",
      "kitchen: 35 unique columns\n",
      "  Examples: ['Average Polygon Area', 'Pre-clipped Polygons/Second', 'GPU % Bus Busy', 'SP Memory Read (Bytes/Second)', '% Vertex Fetch Stall']\n",
      "\n",
      "lab: 46 unique columns\n",
      "  Examples: ['% Texture Fetch Stall', 'Average Polygon Area', 'Pre-clipped Polygons/Second', 'cpu-cycles', 'SP Memory Read (Bytes/Second)']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load one CSV from each room type to see what columns they have\n",
    "cleaned_path = Path(\"meta_scan_csvs/cleaned\")\n",
    "\n",
    "sample_csvs = {\n",
    "    'blinds': 'blinds/blinds_1_cleaned.csv',\n",
    "    'blinds_up': 'blinds_up/blinds_up_1_cleaned.csv',\n",
    "    'hallway': 'hallway/hallway_1_cleaned.csv',\n",
    "    'kitchen': 'kitchen/kitchen_1_cleaned.csv',\n",
    "    'lab': 'lab/lab_1_cleaned.csv'\n",
    "}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ANALYZING SENSOR COLUMNS ACROSS ROOMS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_columns = []\n",
    "for room, csv_path in sample_csvs.items():\n",
    "    df = pd.read_csv(cleaned_path / csv_path)\n",
    "    cols = [c for c in df.columns if c != 'Time (s)']\n",
    "    all_columns.append(set(cols))\n",
    "    print(f\"\\n{room}: {len(cols)} columns\")\n",
    "    print(f\"  Sample columns: {cols[:5]}\")\n",
    "\n",
    "# Find common columns across all rooms\n",
    "common_columns = set.intersection(*all_columns)\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(f\"COMMON COLUMNS ACROSS ALL ROOMS: {len(common_columns)}\")\n",
    "print(\"=\" * 80)\n",
    "print(sorted(common_columns))\n",
    "\n",
    "# Find unique columns per room\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(\"UNIQUE COLUMNS PER ROOM\")\n",
    "print(\"=\" * 80)\n",
    "for i, (room, csv_path) in enumerate(sample_csvs.items()):\n",
    "    unique = all_columns[i] - common_columns\n",
    "    print(f\"\\n{room}: {len(unique)} unique columns\")\n",
    "    if len(unique) > 0:\n",
    "        print(f\"  Examples: {list(unique)[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53af098a-7cdc-48d1-bf1d-8b91accd53b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROCESSING TRAIN SET (COMMON FEATURES ONLY)\n",
      "================================================================================\n",
      "\n",
      "lab_person_3_cleaned.csv: 434 rows → 5 windows (22 features)\n",
      "lab_2_cleaned.csv: 438 rows → 5 windows (22 features)\n",
      "blinds_up_person_1_cleaned.csv: 2042 rows → 27 windows (22 features)\n",
      "blinds_up_person_3_cleaned.csv: 493 rows → 6 windows (22 features)\n",
      "blinds_up_motion_5_cleaned.csv: 2109 rows → 28 windows (22 features)\n",
      "kitchen_object_1_cleaned.csv: 2005 rows → 26 windows (22 features)\n",
      "blinds_5_cleaned.csv: 427 rows → 5 windows (22 features)\n",
      "hallway_person_5_cleaned.csv: 1974 rows → 26 windows (22 features)\n",
      "blinds_motion_2_cleaned.csv: 452 rows → 6 windows (22 features)\n",
      "lab_5_cleaned.csv: 1980 rows → 26 windows (22 features)\n",
      "hallway_object_5_cleaned.csv: 455 rows → 6 windows (22 features)\n",
      "blinds_up_3_cleaned.csv: 1795 rows → 23 windows (22 features)\n",
      "lab_object_5_cleaned.csv: 447 rows → 5 windows (22 features)\n",
      "lab_motion_2_cleaned.csv: 453 rows → 6 windows (22 features)\n",
      "blinds_person_4_cleaned.csv: 482 rows → 6 windows (22 features)\n",
      "blinds_up_2_cleaned.csv: 1775 rows → 23 windows (22 features)\n",
      "blinds_up_person_5_cleaned.csv: 461 rows → 6 windows (22 features)\n",
      "blinds_1_cleaned.csv: 2184 rows → 29 windows (22 features)\n",
      "lab_motion_1_cleaned.csv: 423 rows → 5 windows (22 features)\n",
      "hallway_motion_2_cleaned.csv: 482 rows → 6 windows (22 features)\n",
      "blinds_up_4_cleaned.csv: 1798 rows → 23 windows (22 features)\n",
      "blinds_person_1_cleaned.csv: 466 rows → 6 windows (22 features)\n",
      "blinds_object_1_cleaned.csv: 2044 rows → 27 windows (22 features)\n",
      "blinds_up_object_3_cleaned.csv: 2013 rows → 26 windows (22 features)\n",
      "lab_3_cleaned.csv: 474 rows → 6 windows (22 features)\n",
      "kitchen_8_cleaned.csv: 451 rows → 6 windows (22 features)\n",
      "kitchen_2_cleaned.csv: 447 rows → 5 windows (22 features)\n",
      "hallway_person_4_cleaned.csv: 2129 rows → 28 windows (22 features)\n",
      "hallway_object_4_cleaned.csv: 457 rows → 6 windows (22 features)\n",
      "lab_motion_3_cleaned.csv: 479 rows → 6 windows (22 features)\n",
      "kitchen_9_cleaned.csv: 2108 rows → 28 windows (22 features)\n",
      "hallway_5_cleaned.csv: 1981 rows → 26 windows (22 features)\n",
      "blinds_3_cleaned.csv: 1919 rows → 25 windows (22 features)\n",
      "lab_person_4_cleaned.csv: 378 rows → 5 windows (22 features)\n",
      "kitchen_1_cleaned.csv: 439 rows → 5 windows (22 features)\n",
      "kitchen_person_5_cleaned.csv: 412 rows → 5 windows (22 features)\n",
      "kitchen_7_cleaned.csv: 1974 rows → 26 windows (22 features)\n",
      "blinds_up_object_5_cleaned.csv: 2079 rows → 27 windows (22 features)\n",
      "blinds_up_motion_3_cleaned.csv: 472 rows → 6 windows (22 features)\n",
      "lab_object_3_cleaned.csv: 469 rows → 6 windows (22 features)\n",
      "kitchen_motion_3_cleaned.csv: 1937 rows → 25 windows (22 features)\n",
      "hallway_motion_1_cleaned.csv: 467 rows → 6 windows (22 features)\n",
      "kitchen_object_4_cleaned.csv: 1997 rows → 26 windows (22 features)\n",
      "blinds_up_motion_1_cleaned.csv: 467 rows → 6 windows (22 features)\n",
      "kitchen_10_cleaned.csv: 2190 rows → 29 windows (22 features)\n",
      "hallway_4_cleaned.csv: 438 rows → 5 windows (22 features)\n",
      "blinds_object_5_cleaned.csv: 2036 rows → 27 windows (22 features)\n",
      "kitchen_motion_5_cleaned.csv: 497 rows → 6 windows (22 features)\n",
      "kitchen_person_3_cleaned.csv: 1917 rows → 25 windows (22 features)\n",
      "blinds_motion_3_cleaned.csv: 464 rows → 6 windows (22 features)\n",
      "blinds_up_object_2_cleaned.csv: 1981 rows → 26 windows (22 features)\n",
      "lab_object_4_cleaned.csv: 392 rows → 5 windows (22 features)\n",
      "hallway_motion_3_cleaned.csv: 449 rows → 5 windows (22 features)\n",
      "hallway_object_2_cleaned.csv: 1931 rows → 25 windows (22 features)\n",
      "blinds_motion_4_cleaned.csv: 436 rows → 5 windows (22 features)\n",
      "hallway_1_cleaned.csv: 409 rows → 5 windows (22 features)\n",
      "kitchen_motion_4_cleaned.csv: 443 rows → 5 windows (22 features)\n",
      "hallway_2_cleaned.csv: 407 rows → 5 windows (22 features)\n",
      "kitchen_person_1_cleaned.csv: 2133 rows → 28 windows (22 features)\n",
      "blinds_up_1_cleaned.csv: 103 rows → 1 windows (22 features)\n",
      "kitchen_5_cleaned.csv: 1923 rows → 25 windows (22 features)\n",
      "blinds_object_4_cleaned.csv: 455 rows → 6 windows (22 features)\n",
      "kitchen_object_3_cleaned.csv: 2015 rows → 26 windows (22 features)\n",
      "lab_motion_5_cleaned.csv: 2028 rows → 27 windows (22 features)\n",
      "blinds_motion_1_cleaned.csv: 2004 rows → 26 windows (22 features)\n",
      "blinds_2_cleaned.csv: 2060 rows → 27 windows (22 features)\n",
      "blinds_object_2_cleaned.csv: 443 rows → 5 windows (22 features)\n",
      "kitchen_person_2_cleaned.csv: 501 rows → 6 windows (22 features)\n",
      "hallway_person_2_cleaned.csv: 1996 rows → 26 windows (22 features)\n",
      "lab_person_1_cleaned.csv: 440 rows → 5 windows (22 features)\n",
      "blinds_up_person_2_cleaned.csv: 1979 rows → 26 windows (22 features)\n",
      "hallway_object_1_cleaned.csv: 2724 rows → 36 windows (22 features)\n",
      "kitchen_motion_1_cleaned.csv: 417 rows → 5 windows (22 features)\n",
      "blinds_up_object_1_cleaned.csv: 1946 rows → 25 windows (22 features)\n",
      "blinds_up_motion_4_cleaned.csv: 2005 rows → 26 windows (22 features)\n",
      "kitchen_3_cleaned.csv: 485 rows → 6 windows (22 features)\n",
      "hallway_motion_5_cleaned.csv: 458 rows → 6 windows (22 features)\n",
      "lab_person_5_cleaned.csv: 471 rows → 6 windows (22 features)\n",
      "lab_object_1_cleaned.csv: 2046 rows → 27 windows (22 features)\n",
      "lab_4_cleaned.csv: 471 rows → 6 windows (22 features)\n",
      "blinds_person_3_cleaned.csv: 477 rows → 6 windows (22 features)\n",
      "hallway_person_3_cleaned.csv: 495 rows → 6 windows (22 features)\n",
      "blinds_person_2_cleaned.csv: 446 rows → 5 windows (22 features)\n",
      "kitchen_object_5_cleaned.csv: 476 rows → 6 windows (22 features)\n",
      "\n",
      "================================================================================\n",
      "TRAIN SUMMARY\n",
      "================================================================================\n",
      "Total CSVs processed: 84\n",
      "Total windows created: 1215\n",
      "Windows per CSV (avg): 14.5\n",
      "Features per window: 22 (common features only)\n",
      "\n",
      "✓ Saved to: meta_scan_csvs\\windowed_data\\train_windows_common.pkl\n",
      "\n",
      "Windows by room type:\n",
      "room_type\n",
      "blinds       217\n",
      "blinds_up    305\n",
      "hallway      223\n",
      "kitchen      319\n",
      "lab          151\n",
      "dtype: int64\n",
      "\n",
      "================================================================================\n",
      "PROCESSING TEST SET (COMMON FEATURES ONLY)\n",
      "================================================================================\n",
      "\n",
      "blinds_up_5_cleaned.csv: 101 rows → 1 windows (22 features)\n",
      "hallway_motion_4_cleaned.csv: 1981 rows → 26 windows (22 features)\n",
      "blinds_motion_5_cleaned.csv: 477 rows → 6 windows (22 features)\n",
      "kitchen_object_2_cleaned.csv: 426 rows → 5 windows (22 features)\n",
      "blinds_up_person_4_cleaned.csv: 425 rows → 5 windows (22 features)\n",
      "lab_person_2_cleaned.csv: 2179 rows → 29 windows (22 features)\n",
      "kitchen_person_4_cleaned.csv: 477 rows → 6 windows (22 features)\n",
      "blinds_object_3_cleaned.csv: 443 rows → 5 windows (22 features)\n",
      "lab_motion_4_cleaned.csv: 455 rows → 6 windows (22 features)\n",
      "blinds_person_5_cleaned.csv: 449 rows → 5 windows (22 features)\n",
      "kitchen_4_cleaned.csv: 1874 rows → 24 windows (22 features)\n",
      "lab_1_cleaned.csv: 1925 rows → 25 windows (22 features)\n",
      "hallway_3_cleaned.csv: 457 rows → 6 windows (22 features)\n",
      "kitchen_motion_2_cleaned.csv: 1899 rows → 25 windows (22 features)\n",
      "blinds_4_cleaned.csv: 449 rows → 5 windows (22 features)\n",
      "kitchen_6_cleaned.csv: 401 rows → 5 windows (22 features)\n",
      "blinds_up_object_4_cleaned.csv: 473 rows → 6 windows (22 features)\n",
      "hallway_object_3_cleaned.csv: 1953 rows → 26 windows (22 features)\n",
      "lab_object_2_cleaned.csv: 1970 rows → 26 windows (22 features)\n",
      "hallway_person_1_cleaned.csv: 452 rows → 6 windows (22 features)\n",
      "blinds_up_motion_2_cleaned.csv: 2094 rows → 27 windows (22 features)\n",
      "\n",
      "================================================================================\n",
      "TEST SUMMARY\n",
      "================================================================================\n",
      "Total CSVs processed: 21\n",
      "Total windows created: 275\n",
      "Windows per CSV (avg): 13.1\n",
      "Features per window: 22 (common features only)\n",
      "\n",
      "✓ Saved to: meta_scan_csvs\\windowed_data\\test_windows_common.pkl\n",
      "\n",
      "Windows by room type:\n",
      "room_type\n",
      "blinds       21\n",
      "blinds_up    39\n",
      "hallway      64\n",
      "kitchen      65\n",
      "lab          86\n",
      "dtype: int64\n",
      "\n",
      "================================================================================\n",
      "WINDOWING COMPLETE (COMMON FEATURES)\n",
      "================================================================================\n",
      "Training windows: 1215\n",
      "Testing windows: 275\n",
      "Features per window: 22\n",
      "No padding needed - all windows have same shape!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the common columns (from the analysis above)\n",
    "COMMON_COLUMNS = [\n",
    "    'app_gpu_ms', 'app_rss_mb', 'app_uss_mb', 'app_vss_mb', 'application_layer_count', \n",
    "    'application_prediction_milliseconds', 'available_memory_mb', 'cpu_frequency_mhz', \n",
    "    'cpu_level', 'cpu_util_0', 'cpu_util_1', 'cpu_util_2', 'cpu_util_3', 'cpu_util_4', \n",
    "    'cpu_util_5', 'display_refresh_rate', 'gpu_frequency_mhz', 'gpu_level', 'gpu_util', \n",
    "    'mem_frequency_mhz', 'stale_frames_per_second', 'timewarp_gpu_ms'\n",
    "]\n",
    "\n",
    "def create_windows(df, window_size=75):\n",
    "    \"\"\"\n",
    "    Create non-overlapping tumbling windows from a time series dataframe.\n",
    "    Returns a list of window dataframes.\n",
    "    \"\"\"\n",
    "    num_windows = len(df) // window_size\n",
    "    windows = []\n",
    "    \n",
    "    for i in range(num_windows):\n",
    "        start_idx = i * window_size\n",
    "        end_idx = start_idx + window_size\n",
    "        window = df.iloc[start_idx:end_idx].copy()\n",
    "        windows.append(window)\n",
    "    \n",
    "    return windows\n",
    "\n",
    "def process_dataset(metadata_df, output_dir, dataset_name):\n",
    "    \"\"\"\n",
    "    Process all CSVs in a dataset (train or test), create windows using ONLY common features.\n",
    "    \"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    all_windows_data = []\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"PROCESSING {dataset_name.upper()} SET (COMMON FEATURES ONLY)\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "    \n",
    "    for idx, row in metadata_df.iterrows():\n",
    "        csv_path = Path(row['filepath'])\n",
    "        room_type = row['room_type']\n",
    "        scan_type = row['scan_type']\n",
    "        trial_number = row['trial_number']\n",
    "        \n",
    "        # Load CSV\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Select ONLY common columns (no Time column)\n",
    "        # Check which common columns exist in this CSV\n",
    "        available_common = [col for col in COMMON_COLUMNS if col in df.columns]\n",
    "        \n",
    "        if len(available_common) != len(COMMON_COLUMNS):\n",
    "            missing = set(COMMON_COLUMNS) - set(available_common)\n",
    "            print(f\"WARNING: {row['filename']} missing columns: {missing}\")\n",
    "        \n",
    "        df = df[available_common]\n",
    "        \n",
    "        # Create windows\n",
    "        windows = create_windows(df, window_size=75)\n",
    "        \n",
    "        print(f\"{row['filename']}: {len(df)} rows → {len(windows)} windows (22 features)\")\n",
    "        \n",
    "        # Save each window with metadata\n",
    "        for window_idx, window_df in enumerate(windows):\n",
    "            window_data = {\n",
    "                'original_filename': row['filename'],\n",
    "                'room_type': room_type,\n",
    "                'scan_type': scan_type,\n",
    "                'trial_number': trial_number,\n",
    "                'window_id': window_idx,\n",
    "                'window_data': window_df.values  # Store as numpy array\n",
    "            }\n",
    "            all_windows_data.append(window_data)\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"{dataset_name.upper()} SUMMARY\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(f\"Total CSVs processed: {len(metadata_df)}\")\n",
    "    print(f\"Total windows created: {len(all_windows_data)}\")\n",
    "    print(f\"Windows per CSV (avg): {len(all_windows_data) / len(metadata_df):.1f}\")\n",
    "    print(f\"Features per window: 22 (common features only)\")\n",
    "    \n",
    "    # Save as pickle for easy loading later\n",
    "    windows_df = pd.DataFrame(all_windows_data)\n",
    "    output_file = output_path / f\"{dataset_name}_windows_common.pkl\"\n",
    "    windows_df.to_pickle(output_file)\n",
    "    print(f\"\\n✓ Saved to: {output_file}\")\n",
    "    \n",
    "    # Show distribution\n",
    "    print(f\"\\nWindows by room type:\")\n",
    "    print(windows_df.groupby('room_type').size())\n",
    "    \n",
    "    return windows_df\n",
    "\n",
    "# Load train and test metadata\n",
    "train_metadata = pd.read_csv(\"meta_scan_csvs/train_metadata.csv\")\n",
    "test_metadata = pd.read_csv(\"meta_scan_csvs/test_metadata.csv\")\n",
    "\n",
    "# Process training set\n",
    "train_windows = process_dataset(\n",
    "    train_metadata, \n",
    "    \"meta_scan_csvs/windowed_data\", \n",
    "    \"train\"\n",
    ")\n",
    "\n",
    "# Process testing set\n",
    "test_windows = process_dataset(\n",
    "    test_metadata, \n",
    "    \"meta_scan_csvs/windowed_data\", \n",
    "    \"test\"\n",
    ")\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"WINDOWING COMPLETE (COMMON FEATURES)\")\n",
    "print(f\"{'=' * 80}\")\n",
    "print(f\"Training windows: {len(train_windows)}\")\n",
    "print(f\"Testing windows: {len(test_windows)}\")\n",
    "print(f\"Features per window: 22\")\n",
    "print(f\"No padding needed - all windows have same shape!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8664b185-af33-46b8-b9a2-865e3f61edcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 4: ROCKET CLASSIFIER FOR ROOM TYPE (COMMON FEATURES)\n",
      "================================================================================\n",
      "\n",
      "Loading windowed data...\n",
      "Training windows: 1215\n",
      "Testing windows: 275\n",
      "\n",
      "Preparing training data...\n",
      "X_train shape: (1215, 75, 22)\n",
      "  - Samples: 1215\n",
      "  - Time points: 75\n",
      "  - Features (common sensors): 22\n",
      "\n",
      "Preparing testing data...\n",
      "X_test shape: (275, 75, 22)\n",
      "\n",
      "================================================================================\n",
      "CLASS DISTRIBUTION\n",
      "================================================================================\n",
      "\n",
      "Training set:\n",
      "blinds       217\n",
      "blinds_up    305\n",
      "hallway      223\n",
      "kitchen      319\n",
      "lab          151\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Testing set:\n",
      "blinds       21\n",
      "blinds_up    39\n",
      "hallway      64\n",
      "kitchen      65\n",
      "lab          86\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "TRAINING ROCKET CLASSIFIER\n",
      "================================================================================\n",
      "\n",
      "Initializing ROCKET classifier...\n",
      "  - Number of kernels: 10,000\n",
      "  - Random state: 42\n",
      "\n",
      "Fitting ROCKET classifier (this may take a few minutes)...\n",
      "✓ Training complete!\n",
      "\n",
      "================================================================================\n",
      "EVALUATION\n",
      "================================================================================\n",
      "\n",
      "Making predictions on training set...\n",
      "Making predictions on test set...\n",
      "\n",
      "Training Accuracy: 1.0000 (100.00%)\n",
      "Testing Accuracy: 0.7018 (70.18%)\n",
      "\n",
      "================================================================================\n",
      "DETAILED CLASSIFICATION REPORT (TEST SET)\n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      blinds     0.4615    0.5714    0.5106        21\n",
      "   blinds_up     0.4348    0.2564    0.3226        39\n",
      "     hallway     0.7632    0.9062    0.8286        64\n",
      "     kitchen     0.6163    0.8154    0.7020        65\n",
      "         lab     0.9375    0.6977    0.8000        86\n",
      "\n",
      "    accuracy                         0.7018       275\n",
      "   macro avg     0.6427    0.6494    0.6328       275\n",
      "weighted avg     0.7134    0.7018    0.6937       275\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CONFUSION MATRIX (TEST SET)\n",
      "================================================================================\n",
      "           blinds  blinds_up  hallway  kitchen  lab\n",
      "blinds         12          4        1        3    1\n",
      "blinds_up       7         10        2       19    1\n",
      "hallway         1          2       58        1    2\n",
      "kitchen         6          3        3       53    0\n",
      "lab             0          4       12       10   60\n",
      "\n",
      "Rows = Actual, Columns = Predicted\n",
      "\n",
      "================================================================================\n",
      "PER-CLASS ACCURACY\n",
      "================================================================================\n",
      "blinds      : 0.5714 (57.14%)\n",
      "blinds_up   : 0.2564 (25.64%)\n",
      "hallway     : 0.9062 (90.62%)\n",
      "kitchen     : 0.8154 (81.54%)\n",
      "lab         : 0.6977 (69.77%)\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE - NO MODEL SAVED\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 4: ROCKET CLASSIFIER FOR ROOM TYPE (COMMON FEATURES)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load windowed data with common features\n",
    "print(\"\\nLoading windowed data...\")\n",
    "train_windows = pd.read_pickle(\"meta_scan_csvs/windowed_data/train_windows_common.pkl\")\n",
    "test_windows = pd.read_pickle(\"meta_scan_csvs/windowed_data/test_windows_common.pkl\")\n",
    "\n",
    "print(f\"Training windows: {len(train_windows)}\")\n",
    "print(f\"Testing windows: {len(test_windows)}\")\n",
    "\n",
    "# Prepare data for ROCKET (no padding needed!)\n",
    "def prepare_rocket_data(windows_df):\n",
    "    \"\"\"\n",
    "    Convert windowed data to ROCKET format: (n_samples, n_timepoints, n_features)\n",
    "    All windows have the same shape now!\n",
    "    \"\"\"\n",
    "    X = np.stack(windows_df['window_data'].values)  # Stack all windows\n",
    "    y = windows_df['room_type'].values  # Room type labels\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "print(\"\\nPreparing training data...\")\n",
    "X_train, y_train = prepare_rocket_data(train_windows)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"  - Samples: {X_train.shape[0]}\")\n",
    "print(f\"  - Time points: {X_train.shape[1]}\")\n",
    "print(f\"  - Features (common sensors): {X_train.shape[2]}\")\n",
    "\n",
    "print(\"\\nPreparing testing data...\")\n",
    "X_test, y_test = prepare_rocket_data(test_windows)\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CLASS DISTRIBUTION\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nTraining set:\")\n",
    "train_dist = pd.Series(y_train).value_counts().sort_index()\n",
    "print(train_dist)\n",
    "print(f\"\\nTesting set:\")\n",
    "test_dist = pd.Series(y_test).value_counts().sort_index()\n",
    "print(test_dist)\n",
    "\n",
    "# Train ROCKET classifier\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING ROCKET CLASSIFIER\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nInitializing ROCKET classifier...\")\n",
    "print(\"  - Number of kernels: 10,000\")\n",
    "print(\"  - Random state: 42\")\n",
    "\n",
    "rocket_classifier = RocketClassifier(num_kernels=10000, random_state=42)\n",
    "\n",
    "print(\"\\nFitting ROCKET classifier (this may take a few minutes)...\")\n",
    "rocket_classifier.fit(X_train, y_train)\n",
    "print(\"✓ Training complete!\")\n",
    "\n",
    "# Make predictions\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nMaking predictions on training set...\")\n",
    "y_train_pred = rocket_classifier.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"Making predictions on test set...\")\n",
    "y_test_pred = rocket_classifier.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\nTraining Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DETAILED CLASSIFICATION REPORT (TEST SET)\")\n",
    "print(\"=\" * 80)\n",
    "print(classification_report(y_test, y_test_pred, digits=4))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONFUSION MATRIX (TEST SET)\")\n",
    "print(\"=\" * 80)\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "room_types = sorted(np.unique(y_test))\n",
    "cm_df = pd.DataFrame(cm, index=room_types, columns=room_types)\n",
    "print(cm_df)\n",
    "print(\"\\nRows = Actual, Columns = Predicted\")\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PER-CLASS ACCURACY\")\n",
    "print(\"=\" * 80)\n",
    "for i, room_type in enumerate(room_types):\n",
    "    class_accuracy = cm[i, i] / cm[i, :].sum()\n",
    "    print(f\"{room_type:12s}: {class_accuracy:.4f} ({class_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS COMPLETE - NO MODEL SAVED\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd067c21-78e6-4a02-b19a-21cc42039202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
